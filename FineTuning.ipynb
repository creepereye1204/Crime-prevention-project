{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOku3E2XF0M+cdHmmoZBZeI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/creepereye1204/Crime-prevention-project/blob/renewal/FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset/\n",
        "#     anchor/\n",
        "#         anchor1.jpg\n",
        "#         anchor2.jpg\n",
        "#         ...\n",
        "#     positive/\n",
        "#         positive1.jpg\n",
        "#         positive2.jpg\n",
        "#         ...\n",
        "#     negative/\n",
        "#         negative1.jpg\n",
        "#         negative2.jpg\n",
        "#         ...\n"
      ],
      "metadata": {
        "id": "JuW-eOGu2tPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CPU로"
      ],
      "metadata": {
        "id": "5_TFQX1B3GYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctAyHHDL1Yx8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 1. 모델 정의\n",
        "model = InceptionResnetV1(pretrained='vggface2').train()\n",
        "\n",
        "# 2. 트립렛 손실 함수 정의\n",
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        pos_distance = (anchor - positive).pow(2).sum(1)  # 유클리드 거리의 제곱\n",
        "        neg_distance = (anchor - negative).pow(2).sum(1)  # 유클리드 거리의 제곱\n",
        "        loss = torch.relu(pos_distance - neg_distance + self.margin)\n",
        "        return loss.mean()\n",
        "\n",
        "criterion = TripletLoss(margin=1.0)\n",
        "\n",
        "# 3. 옵티마이저 설정\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, anchor_dir, positive_dir, negative_dir, transform=None):\n",
        "        self.anchor_dir = anchor_dir\n",
        "        self.positive_dir = positive_dir\n",
        "        self.negative_dir = negative_dir\n",
        "        self.transform = transform\n",
        "        self.anchor_images = os.listdir(anchor_dir)\n",
        "        self.positive_images = os.listdir(positive_dir)\n",
        "        self.negative_images = os.listdir(negative_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.anchor_images), len(self.positive_images), len(self.negative_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor_path = os.path.join(self.anchor_dir, self.anchor_images[idx])\n",
        "        positive_path = os.path.join(self.positive_dir, self.positive_images[idx])\n",
        "        negative_path = os.path.join(self.negative_dir, self.negative_images[idx])\n",
        "\n",
        "        anchor_image = Image.open(anchor_path).convert('RGB')\n",
        "        positive_image = Image.open(positive_path).convert('RGB')\n",
        "        negative_image = Image.open(negative_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            anchor_image = self.transform(anchor_image)\n",
        "            positive_image = self.transform(positive_image)\n",
        "            negative_image = self.transform(negative_image)\n",
        "\n",
        "        return anchor_image, positive_image, negative_image\n",
        "\n",
        "# 이미지 전처리 변환 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 폴더 경로 설정 (실제 경로로 대체 필요)\n",
        "anchor_dir = 'path/to/dataset/anchor'\n",
        "positive_dir = 'path/to/dataset/positive'\n",
        "negative_dir = 'path/to/dataset/negative'\n",
        "\n",
        "# 데이터 로더 정의\n",
        "dataset = TripletDataset(anchor_dir, positive_dir, negative_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        anchor, positive, negative = data\n",
        "        optimizer.zero_grad()\n",
        "        anchor_embedding = model(anchor)\n",
        "        positive_embedding = model(positive)\n",
        "        negative_embedding = model(negative)\n",
        "        loss = criterion(anchor_embedding, positive_embedding, negative_embedding)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 10 == 9:  # 매 10 미니 배치마다 출력\n",
        "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 10:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# 4. 임베딩 벡터 계산 및 분류 함수 정의\n",
        "def get_embedding(model, image):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        embedding = model(image.unsqueeze(0))\n",
        "    return embedding\n",
        "\n",
        "# 예시: 앵커, 양성, 음성 이미지의 임베딩 벡터 계산\n",
        "anchor_image = transform(Image.open('path/to/anchor_image.jpg').convert('RGB'))\n",
        "positive_image = transform(Image.open('path/to/positive_image.jpg').convert('RGB'))\n",
        "negative_image = transform(Image.open('path/to/negative_image.jpg').convert('RGB'))\n",
        "\n",
        "anchor_embedding = get_embedding(model, anchor_image)\n",
        "positive_embedding = get_embedding(model, positive_image)\n",
        "negative_embedding = get_embedding(model, negative_image)\n",
        "\n",
        "# 유클리드 거리 계산\n",
        "pos_distance = torch.dist(anchor_embedding, positive_embedding, p=2).item()\n",
        "neg_distance = torch.dist(anchor_embedding, negative_embedding, p=2).item()\n",
        "\n",
        "# 임계값을 기준으로 분류\n",
        "threshold = 0.5  # 임계값 설정\n",
        "if pos_distance < threshold:\n",
        "    print(\"Positive (같은 클래스)\")\n",
        "else:\n",
        "    print(\"Negative (다른 클래스)\")\n",
        "\n",
        "print(f'Positive Distance: {pos_distance}')\n",
        "print(f'Negative Distance: {neg_distance}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TPU로"
      ],
      "metadata": {
        "id": "ZWtGB9-z2AI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.data_parallel as dp\n",
        "import torch_xla.utils.serialization as xser\n",
        "\n",
        "# 1. TPU 장치 설정\n",
        "device = xm.xla_device()\n",
        "\n",
        "# 2. 모델 정의\n",
        "model = InceptionResnetV1(pretrained='vggface2').train().to(device)\n",
        "\n",
        "# 3. 트립렛 손실 함수 정의\n",
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        pos_distance = (anchor - positive).pow(2).sum(1)  # 유클리드 거리의 제곱\n",
        "        neg_distance = (anchor - negative).pow(2).sum(1)  # 유클리드 거리의 제곱\n",
        "        loss = torch.relu(pos_distance - neg_distance + self.margin)\n",
        "        return loss.mean()\n",
        "\n",
        "criterion = TripletLoss(margin=1.0)\n",
        "\n",
        "# 4. 옵티마이저 설정\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, anchor_dir, positive_dir, negative_dir, transform=None):\n",
        "        self.anchor_dir = anchor_dir\n",
        "        self.positive_dir = positive_dir\n",
        "        self.negative_dir = negative_dir\n",
        "        self.transform = transform\n",
        "        self.anchor_images = os.listdir(anchor_dir)\n",
        "        self.positive_images = os.listdir(positive_dir)\n",
        "        self.negative_images = os.listdir(negative_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.anchor_images), len(self.positive_images), len(self.negative_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor_path = os.path.join(self.anchor_dir, self.anchor_images[idx])\n",
        "        positive_path = os.path.join(self.positive_dir, self.positive_images[idx])\n",
        "        negative_path = os.path.join(self.negative_dir, self.negative_images[idx])\n",
        "\n",
        "        anchor_image = Image.open(anchor_path).convert('RGB')\n",
        "        positive_image = Image.open(positive_path).convert('RGB')\n",
        "        negative_image = Image.open(negative_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            anchor_image = self.transform(anchor_image)\n",
        "            positive_image = self.transform(positive_image)\n",
        "            negative_image = self.transform(negative_image)\n",
        "\n",
        "        return anchor_image, positive_image, negative_image\n",
        "\n",
        "# 이미지 전처리 변환 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 폴더 경로 설정 (실제 경로로 대체 필요)\n",
        "anchor_dir = 'path/to/dataset/anchor'\n",
        "positive_dir = 'path/to/dataset/positive'\n",
        "negative_dir = 'path/to/dataset/negative'\n",
        "\n",
        "# 데이터 로더 정의\n",
        "dataset = TripletDataset(anchor_dir, positive_dir, negative_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        anchor, positive, negative = data\n",
        "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        anchor_embedding = model(anchor)\n",
        "        positive_embedding = model(positive)\n",
        "        negative_embedding = model(negative)\n",
        "        loss = criterion(anchor_embedding, positive_embedding, negative_embedding)\n",
        "        loss.backward()\n",
        "        xm.optimizer_step(optimizer)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 10 == 9:  # 매 10 미니 배치마다 출력\n",
        "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 10:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# 4. 임베딩 벡터 계산 및 분류 함수 정의\n",
        "def get_embedding(model, image):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        image = image.to(device)\n",
        "        embedding = model(image.unsqueeze(0))\n",
        "    return embedding\n",
        "\n",
        "# 예시: 앵커, 양성, 음성 이미지의 임베딩 벡터 계산\n",
        "anchor_image = transform(Image.open('path/to/anchor_image.jpg').convert('RGB'))\n",
        "positive_image = transform(Image.open('path/to/positive_image.jpg').convert('RGB'))\n",
        "negative_image = transform(Image.open('path/to/negative_image.jpg').convert('RGB'))\n",
        "\n",
        "anchor_embedding = get_embedding(model, anchor_image)\n",
        "positive_embedding = get_embedding(model, positive_image)\n",
        "negative_embedding = get_embedding(model, negative_image)\n",
        "\n",
        "# 유클리드 거리 계산\n",
        "pos_distance = torch.dist(anchor_embedding, positive_embedding, p=2).item()\n",
        "neg_distance = torch.dist(anchor_embedding, negative_embedding, p=2).item()\n",
        "\n",
        "# 임계값을 기준으로 분류\n",
        "threshold = 0.5  # 임계값 설정\n",
        "if pos_distance < threshold:\n",
        "    print(\"Positive (같은 클래스)\")\n",
        "else:\n",
        "    print(\"Negative (다른 클래스)\")\n",
        "\n",
        "print(f'Positive Distance: {pos_distance}')\n",
        "print(f'Negative Distance: {neg_distance}')\n"
      ],
      "metadata": {
        "id": "FKghI9dw3LzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU로"
      ],
      "metadata": {
        "id": "rwOhPEgw3NQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 1. GPU 장치 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. 모델 정의\n",
        "model = InceptionResnetV1(pretrained='vggface2').train().to(device)\n",
        "\n",
        "# 3. 트립렛 손실 함수 정의\n",
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        pos_distance = (anchor - positive).pow(2).sum(1)  # 유클리드 거리의 제곱\n",
        "        neg_distance = (anchor - negative).pow(2).sum(1)  # 유클리드 거리의 제곱\n",
        "        loss = torch.relu(pos_distance - neg_distance + self.margin)\n",
        "        return loss.mean()\n",
        "\n",
        "criterion = TripletLoss(margin=1.0)\n",
        "\n",
        "# 4. 옵티마이저 설정\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, anchor_dir, positive_dir, negative_dir, transform=None):\n",
        "        self.anchor_dir = anchor_dir\n",
        "        self.positive_dir = positive_dir\n",
        "        self.negative_dir = negative_dir\n",
        "        self.transform = transform\n",
        "        self.anchor_images = os.listdir(anchor_dir)\n",
        "        self.positive_images = os.listdir(positive_dir)\n",
        "        self.negative_images = os.listdir(negative_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.anchor_images), len(self.positive_images), len(self.negative_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor_path = os.path.join(self.anchor_dir, self.anchor_images[idx])\n",
        "        positive_path = os.path.join(self.positive_dir, self.positive_images[idx])\n",
        "        negative_path = os.path.join(self.negative_dir, self.negative_images[idx])\n",
        "\n",
        "        anchor_image = Image.open(anchor_path).convert('RGB')\n",
        "        positive_image = Image.open(positive_path).convert('RGB')\n",
        "        negative_image = Image.open(negative_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            anchor_image = self.transform(anchor_image)\n",
        "            positive_image = self.transform(positive_image)\n",
        "            negative_image = self.transform(negative_image)\n",
        "\n",
        "        return anchor_image, positive_image, negative_image\n",
        "\n",
        "# 이미지 전처리 변환 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 폴더 경로 설정 (실제 경로로 대체 필요)\n",
        "anchor_dir = 'path/to/dataset/anchor'\n",
        "positive_dir = 'path/to/dataset/positive'\n",
        "negative_dir = 'path/to/dataset/negative'\n",
        "\n",
        "# 데이터 로더 정의\n",
        "dataset = TripletDataset(anchor_dir, positive_dir, negative_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        anchor, positive, negative = data\n",
        "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        anchor_embedding = model(anchor)\n",
        "        positive_embedding = model(positive)\n",
        "        negative_embedding = model(negative)\n",
        "        loss = criterion(anchor_embedding, positive_embedding, negative_embedding)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 10 == 9:  # 매 10 미니 배치마다 출력\n",
        "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 10:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# 4. 임베딩 벡터 계산 및 분류 함수 정의\n",
        "def get_embedding(model, image):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        image = image.to(device)\n",
        "        embedding = model(image.unsqueeze(0))\n",
        "    return embedding\n",
        "\n",
        "# 예시: 앵커, 양성, 음성 이미지의 임베딩 벡터 계산\n",
        "anchor_image = transform(Image.open('path/to/anchor_image.jpg').convert('RGB'))\n",
        "positive_image = transform(Image.open('path/to/positive_image.jpg').convert('RGB'))\n",
        "negative_image = transform(Image.open('path/to/negative_image.jpg').convert('RGB'))\n",
        "\n",
        "anchor_embedding = get_embedding(model, anchor_image)\n",
        "positive_embedding = get_embedding(model, positive_image)\n",
        "negative_embedding = get_embedding(model, negative_image)\n",
        "\n",
        "# 유클리드 거리 계산\n",
        "pos_distance = torch.dist(anchor_embedding, positive_embedding, p=2).item()\n",
        "neg_distance = torch.dist(anchor_embedding, negative_embedding, p=2).item()\n",
        "\n",
        "# 임계값을 기준으로 분류\n",
        "threshold = 0.5  # 임계값 설정\n",
        "if pos_distance < threshold:\n",
        "    print(\"Positive (같은 클래스)\")\n",
        "else:\n",
        "    print(\"Negative (다른 클래스)\")\n",
        "\n",
        "print(f'Positive Distance: {pos_distance}')\n",
        "print(f'Negative Distance: {neg_distance}')\n"
      ],
      "metadata": {
        "id": "UVZ3jEUn3O8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 크롤링"
      ],
      "metadata": {
        "id": "2mUvurFr5Lv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 검색어 설정\n",
        "query = '한국 연예인'  # 검색어를 변경할 수 있습니다.\n",
        "url = f'https://search.naver.com/search.naver?where=image&sm=tab_jum&query={query}'\n",
        "\n",
        "# 요청 헤더 설정 (네이버는 User-Agent 확인을 통해 봇을 차단할 수 있음)\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# 이미지 URL 수집\n",
        "image_urls = []\n",
        "for img_tag in soup.find_all('img'):\n",
        "    try:\n",
        "        img_url = img_tag['data-source']\n",
        "        image_urls.append(img_url)\n",
        "    except KeyError:\n",
        "        # data-source 속성이 없는 경우 건너뜀\n",
        "        continue\n",
        "\n",
        "# 이미지 다운로드 디렉터리 설정\n",
        "os.makedirs('korean_celeb_images', exist_ok=True)\n",
        "\n",
        "# 이미지 다운로드\n",
        "for i, img_url in enumerate(image_urls):\n",
        "    try:\n",
        "        img_response = requests.get(img_url)\n",
        "        img_response.raise_for_status()  # 요청이 성공했는지 확인\n",
        "        with open(f'korean_celeb_images/korean_celeb_{i}.jpg', 'wb') as file:\n",
        "            file.write(img_response.content)\n",
        "        print(f'Downloaded image {i + 1}')\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f'Failed to download image {i + 1}: {e}')\n",
        "\n",
        "print('이미지 다운로드 완료')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDSQ2uPg5NP8",
        "outputId": "66fdaf8d-eef1-4428-b9ba-52c424cfd46b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이미지 다운로드 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOGJ8EoE6CN8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}